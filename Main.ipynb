{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba6f43f-117d-427a-83dd-9ac645eed334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd366c14-3a26-41af-b1b1-136fc75919a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991bf14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader (train_data,\n",
    "                         batch_size = 100,\n",
    "                         shuffle = True,\n",
    "                         num_workers = 1),\n",
    "    \n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size = 100,\n",
    "                       shuffle = True,\n",
    "                       num_workers = 1)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68391f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fcl = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fcl(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e859d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45197efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tester\\AppData\\Local\\Temp\\ipykernel_15156\\756626896.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t1.591875\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t1.618967\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t1.555238\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t1.539209\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.562695\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.535926\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.560713\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.582056\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.594901\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.511962\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.579550\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.550782\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.551860\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.585585\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.571479\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.547976\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.572275\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.535949\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.582677\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.541852\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.557799\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.568006\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.553181\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.558060\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.553141\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.548982\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.575511\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.495563\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.581607\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.535236\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9577/10000 (96%\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.552291\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.536486\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.538236\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.556744\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.593044\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.557410\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.602296\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.510408\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.556965\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.566664\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.547380\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.539282\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.542227\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.548482\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.554303\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.565748\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.527205\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.552185\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.537592\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.573994\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.537046\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.507370\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.529041\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.510367\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.557164\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.608907\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.543942\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.509508\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.546669\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.539651\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9646/10000 (96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcbb575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tester\\AppData\\Local\\Temp\\ipykernel_15156\\756626896.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Draw a digit\")\n",
    "\n",
    "# Set up the canvas\n",
    "canvas = tk.Canvas(root, width=200, height=200, bg=\"white\")\n",
    "canvas.pack()\n",
    "\n",
    "# Create an empty image for drawing\n",
    "image = Image.new(\"L\", (200, 200), color=255)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Function to draw on the canvas\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    canvas.create_oval(x1, y1, x2, y2, fill=\"black\", width=5)\n",
    "    draw.line([x1, y1, x2, y2], fill=0, width=5)\n",
    "\n",
    "# Bind the paint function to the left mouse button\n",
    "canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "# Function to preprocess the image and make a prediction\n",
    "def predict():\n",
    "    # Resize and invert the image (black background)\n",
    "    resized_image = image.resize((28, 28))\n",
    "    inverted_image = ImageOps.invert(resized_image)\n",
    "    \n",
    "    # Convert the image to a numpy array and normalize it\n",
    "    image_array = np.array(inverted_image) / 255.0\n",
    "    image_array = image_array.astype(np.float32)\n",
    "    image_array = image_array[np.newaxis, np.newaxis, :, :]  # Add batch and channel dimensions\n",
    "\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    input_tensor = torch.from_numpy(image_array).to(device)\n",
    "    \n",
    "    # Make a prediction using the neural network\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prediction = F.softmax(output, dim=1).argmax(dim=1).item()\n",
    "\n",
    "    # Display the prediction\n",
    "    result_label.config(text=f\"Prediction: {prediction}\")\n",
    "\n",
    "# Load your trained model\n",
    "model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Button to make a prediction\n",
    "predict_button = tk.Button(root, text=\"Predict\", command=predict)\n",
    "predict_button.pack()\n",
    "\n",
    "# Label to display the result\n",
    "result_label = tk.Label(root, text=\"Prediction: \")\n",
    "result_label.pack()\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
